{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2022 Semester 1\n",
    "\n",
    "## Assignment 2: Sentiment Classification of Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the CSV datafiles (Train and Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"Train.csv\", sep=',')\n",
    "train_data.drop(columns = 'Unnamed: 0', inplace = True)\n",
    "test_data = pd.read_csv(\"Test.csv\", sep=',')\n",
    "\n",
    "# separating instance and label for Train and Test\n",
    "X_train_raw = train_data['text']\n",
    "Y_train = train_data['sentiment']\n",
    "X_test_raw = test_data['text']\n",
    "\n",
    "#check the result\n",
    "print(\"Train length:\",len(X_train_raw))\n",
    "print(\"Test length:\",len(X_test_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the distribution of class labels\n",
    "count = Y_train.value_counts()\n",
    "print(\"Number of tweets of each class\")\n",
    "print(count)\n",
    "\n",
    "sns.barplot(x=['negative', 'neutral', 'positive'], y=[count['negative'], count['neutral'], count['positive']])\n",
    "plt.xticks(fontsize=14)\n",
    "plt.title('Number of instances of each class', fontsize=16)\n",
    "plt.savefig(\"distribution.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- expand contractions\n",
    "- remove links\n",
    "- remove non-ASCII characters, punctuations, spacing characters from the text\n",
    "- remove words that are only a single character long or contain digits\n",
    "- tokenize words and remove stopwords\n",
    "- Snowball Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install unidecode\n",
    "# pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import unidecode\n",
    "import contractions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_digit(word):\n",
    "    '''\n",
    "    Check and return true if a word contains digits.\n",
    "    '''\n",
    "    for char in word:\n",
    "        if char.isdigit():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    '''\n",
    "    Preprocess the raw text data into tokenized lists of words.\n",
    "    Input: a single tweet\n",
    "    Output: a list of filtered terms\n",
    "    '''\n",
    "    # expand contractions (e.g. can't -> cannot)\n",
    "    revised_text = contractions.fix(text)\n",
    "    \n",
    "    # remove links from the text\n",
    "    revised_text = re.sub(r'\\w+:\\/{2}[\\w-]+(\\.[\\w\\/-]+)*', '', revised_text)\n",
    "    \n",
    "    # remove non-ASCII characters\n",
    "    revised_text = re.sub(r'[^\\x00-\\x7F]', r' ', revised_text)\n",
    "\n",
    "    # remove any spacing characters\n",
    "    revised_text = re.sub(r'[\\n\\t\\s]+', r' ', revised_text)\n",
    "    \n",
    "    # tokenize the text into words\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    tokens = tokenizer.tokenize(revised_text)\n",
    "    \n",
    "    # remove stopwords, but keep 'not' and 'no' in text as they indicate negation\n",
    "    keep = ['no', 'not']\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    revised_lst = [w for w in tokens if w in keep or w not in stop_words]\n",
    "    \n",
    "    # remove punctuations in text\n",
    "    revised_lst = [w for w in revised_lst if w not in string.punctuation]\n",
    "    \n",
    "    # remove words that contain numbers\n",
    "    revised_lst = [w for w in revised_lst if not contain_digit(w)]\n",
    "    \n",
    "    # remove words that are only a single character long\n",
    "    # reduce words back into their stem form except hashtags\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    revised_lst = [w if w[0] == '#' else stemmer.stem(w) for w in revised_lst if len(w) != 1]\n",
    "\n",
    "    return revised_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram_tfidf(X_train_raw, X_test_raw, n = 1):\n",
    "    '''\n",
    "    Apply n-gram algorithms while doing TF-IDF vectorization.\n",
    "    n: {1: 'unigram', 2: 'bigram', n: '1-n gram'}, default = 1\n",
    "    '''\n",
    "    if n==1:\n",
    "        # unigram\n",
    "        tfidf_vectorizer = TfidfVectorizer(analyzer=preprocess)\n",
    "        X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_raw)\n",
    "        X_test_tfidf = tfidf_vectorizer.transform(X_test_raw)\n",
    "        \n",
    "    else:\n",
    "        # join the tokenized words into sentences\n",
    "        train_x_cleaned = []\n",
    "        test_cleaned = []\n",
    "        \n",
    "        for i in X_train_raw:\n",
    "            train_x_cleaned.append(' '.join(preprocess(i)))\n",
    "        for i in X_test_raw:\n",
    "            test_cleaned.append(' '.join(preprocess(i)))\n",
    "    \n",
    "        if n==2:\n",
    "            # bigram\n",
    "            vectorizer = TfidfVectorizer(ngram_range=(2,2))\n",
    "            X_train_tfidf = vectorizer.fit_transform(train_x_cleaned)\n",
    "            X_test_tfidf = vectorizer.transform(test_cleaned)\n",
    "        \n",
    "        else:\n",
    "            # 1-n gram\n",
    "            vectorizer = TfidfVectorizer(ngram_range=(1,n))\n",
    "            X_train_tfidf = vectorizer.fit_transform(train_x_cleaned)\n",
    "            X_test_tfidf = vectorizer.transform(test_cleaned)\n",
    "            \n",
    "    return X_train_tfidf, X_test_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(X_train_tfidf, Y_train, sampling_method = None):\n",
    "    '''\n",
    "    Apply sampling method to the cleaned training data.\n",
    "    sampling_method: {'under', 'over', None}, default = None\n",
    "        - 'under': random under sampling\n",
    "        - 'over': random over sampling\n",
    "        - None: no sampling method applied \n",
    "    '''\n",
    "    if sampling_method == 'under':\n",
    "        rus = RandomUnderSampler(random_state=42) \n",
    "        return rus.fit_resample(X_train_tfidf, Y_train)\n",
    "    elif sampling_method == 'over':\n",
    "        ros = RandomOverSampler(random_state=42)\n",
    "        return ros.fit_resample(X_train_tfidf, Y_train)\n",
    "    else:\n",
    "        return X_train_tfidf, Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kBest_chi2(i: int, X_train_smp, Y_train, X_test_tfidf):\n",
    "    '''\n",
    "    Select the first i best features using Chi-square test. \n",
    "    '''\n",
    "    x2 = SelectKBest(chi2, k=i)\n",
    "    X_train_kBest = x2.fit_transform(X_train_smp,Y_train)\n",
    "    X_test_kBest = x2.transform(X_test_tfidf)\n",
    "    return X_train_kBest, X_test_kBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Test and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def apply_model(clf, X_train, y_train, X_val, y_val):\n",
    "    '''\n",
    "    Fit a classifier to the training data and use the model to predict the test data.\n",
    "    '''\n",
    "    clf.fit(X_train, y_train)\n",
    "    prediction = clf.predict(X_val)\n",
    "    evaluate(y_val, prediction)\n",
    "    return \n",
    "\n",
    "def evaluate(y_test, prediction):\n",
    "    '''\n",
    "    Generate evaluation metrics.\n",
    "    '''\n",
    "    print(classification_report(y_test, prediction))\n",
    "    \n",
    "    # plot confusion matrix\n",
    "    cm = confusion_matrix(y_test, prediction)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=plt.cm.Blues, cbar=False)\n",
    "    plt.xlabel('Prediction', fontsize=14)\n",
    "    plt.ylabel('Actual label', fontsize=14)\n",
    "    plt.title('Confusion matrix', fontsize=16)\n",
    "    plt.xticks(np.arange(3), labels = ['negative', 'neutral', 'positive'], fontsize=12)\n",
    "    plt.yticks(np.arange(3), labels = ['negative', 'neutral', 'positive'], fontsize=12, rotation=0)\n",
    "    plt.savefig(\"cm.png\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split & apply tfidf vectorization\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_raw, Y_train, test_size=0.3, random_state=42)\n",
    "X_train_tfidf, X_val_tfidf = n_gram_tfidf(X_train, X_val, n=1)  # adjust n-gram approach here\n",
    "feature_size = X_train_tfidf.shape[1]\n",
    "print(\"Train feature space size (using TFIDF):\",X_train_tfidf.shape)\n",
    "print(\"Test feature space size (using TFIDF):\",X_val_tfidf.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "# sampling \n",
    "X_train_smp, Y_train_smp = sampling(X_train_tfidf, y_train, sampling_method = 'under') # adjust sampling methods here\n",
    "\n",
    "# sub-sample the validation set to obtain a balanced dataset\n",
    "X_val_tfidf, y_val = sampling(X_val_tfidf, y_val, sampling_method = 'under')\n",
    "print(\"New train class distribution after sampling:\", Counter(Y_train_smp))\n",
    "print(\"New test class distribution after sampling:\", Counter(y_val))\n",
    "print(\"\\n\")\n",
    "\n",
    "# choose k best (top 10%) features using chi2 test\n",
    "X_train_kBest, X_val_kBest = kBest_chi2(int(0.1*feature_size), X_train_smp, Y_train_smp, X_val_tfidf)\n",
    "print(\"Train feature space size (after feature selection):\", X_train_kBest.shape)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-R (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record the how long does the model take to train and test the data\n",
    "t0 = time.time()\n",
    "\n",
    "zero_r = DummyClassifier(strategy=\"most_frequent\")\n",
    "apply_model(zero_r, X_train_kBest, Y_train_smp, X_val_kBest, y_val)\n",
    "\n",
    "t1 = time.time() - t0\n",
    "print(\"Time to run the model is:\", t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "bnb = BernoulliNB()\n",
    "apply_model(bnb, X_train_kBest, Y_train_smp, X_val_kBest, y_val)\n",
    "t1 = time.time() - t0\n",
    "print(\"Time to run the model is:\", t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "knn5 = KNeighborsClassifier(n_neighbors=5)\n",
    "apply_model(knn5, X_train_kBest, Y_train_smp, X_val_kBest, y_val)\n",
    "t1 = time.time() - t0\n",
    "print(\"Time to run the model is:\", t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "lg_clf = LogisticRegression(solver='saga', multi_class='multinomial', C=6, \n",
    "                            class_weight='balanced', max_iter=1000, penalty = 'l2')\n",
    "apply_model(lg_clf, X_train_kBest, Y_train_smp, X_val_kBest, y_val)\n",
    "t1 = time.time() - t0\n",
    "print(\"Time to run the model is:\", t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "svm = SVC(kernel='rbf', C=5, decision_function_shape='ovo')\n",
    "apply_model(svm, X_train_kBest, Y_train_smp, X_val_kBest, y_val)\n",
    "t1 = time.time() - t0\n",
    "print(\"Time to run the model is:\", t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "estimators = {\n",
    "    ('lg', LogisticRegression(solver='saga', multi_class='multinomial', C=6, max_iter=1000, penalty = 'l2')),\n",
    "    ('svm', SVC(kernel='rbf', C=5)),\n",
    "    ('bnb', BernoulliNB()),\n",
    "}\n",
    "\n",
    "stk_clf = StackingClassifier(estimators, final_estimator=LogisticRegression(solver='saga', \n",
    "                            multi_class='multinomial', C=6, max_iter=10000, penalty = 'l2'))\n",
    "\n",
    "apply_model(stk_clf, X_train_kBest, Y_train_smp, X_val_kBest, y_val)\n",
    "t1 = time.time() - t0\n",
    "print(\"Time to run the model is:\", t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "- Chooing k for k Best feature selection\n",
    "- N-gram & sampling methods comparison\n",
    "- Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line(df, filename, title, xlabel, ylabel):\n",
    "    '''\n",
    "    Produce a line plot for a given dataframe.\n",
    "    Print and save the graph to the given filename.\n",
    "    '''\n",
    "    sns.lineplot(data = df, dashes = False)\n",
    "    plt.title(title, size = 16)\n",
    "    plt.xlabel(xlabel= xlabel, fontsize = 14)\n",
    "    plt.ylabel(ylabel = ylabel, fontsize = 14)\n",
    "    plt.legend(fontsize = 10)\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def accuracy_k(n_gram, sampling_method, X_train_raw, Y_train):\n",
    "    '''\n",
    "    Iterate over multiple k values and plot accuracy of each model with respect to k.\n",
    "    '''\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_raw, Y_train, test_size=0.3, random_state=42)\n",
    "    X_train_tfidf, X_val_tfidf = n_gram_tfidf(X_train, X_val, n_gram)\n",
    "    feature_size = X_train_tfidf.shape[1]\n",
    "    X_train_smp, Y_train_smp = sampling(X_train_tfidf, y_train, sampling_method)\n",
    "    \n",
    "    # sub-sample the validation set to obtain a balanced dataset\n",
    "    X_val_tfidf, y_val = sampling(X_val_tfidf, y_val, sampling_method = 'under')\n",
    "    \n",
    "    clf_list = [bnb, knn5, lg_clf, svm, stk_clf]\n",
    "    acc_list = []\n",
    "    k_val = [0.01, 0.025, 0.05, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.7, 1]\n",
    "    \n",
    "    for clf in clf_list:\n",
    "        acc = []\n",
    "        for k in k_val:\n",
    "            X_train_kBest, X_val_kBest = kBest_chi2(int(k*feature_size), X_train_smp, Y_train_smp, X_val_tfidf)\n",
    "            \n",
    "            clf.fit(X_train_kBest, Y_train_smp)\n",
    "            acc.append(clf.score(X_val_kBest, y_val))\n",
    "        \n",
    "        # print(k_val)\n",
    "        # print(acc)\n",
    "        acc_list.append(acc)\n",
    "        \n",
    "    data = {'Top % features': [100*i for i in k_val], 'BNB': acc_list[0],\n",
    "            'KNN5': acc_list[1], 'LG': acc_list[2], 'SVM': acc_list[3], 'STK': acc_list[4]}\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.set_index('Top % features')\n",
    "    \n",
    "    # plot the accuracy of each model versus different values of k\n",
    "    plot_line(df, filename=\"kVsAcc.png\", title=\"K value vs Accuracy\", xlabel='Top % features', ylabel='Accuracy')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def preprocess_cmp(scoring = 'accuracy'):\n",
    "    '''\n",
    "    For each model, generate the accuracy/ macro-avg f1 score for every combination \n",
    "    of preprocessing techniques (n-gram & sampling).\n",
    "    Parameter:\n",
    "        scoring: {'accuracy', 'f1'}, default = 'accuracy'\n",
    "    '''\n",
    "    n_gram_choice = [1, 2, 3]\n",
    "    sample = [None, 'under', 'over']\n",
    "    df_dict = dict()\n",
    "\n",
    "    for clf in list(clf_dict.keys())[1:]:\n",
    "        acc_list = []\n",
    "        f1_list = []\n",
    "        for n in n_gram_choice:\n",
    "            acc = []\n",
    "            f1 = []\n",
    "            for sm in sample:\n",
    "                X_train, X_val, y_train, y_val = train_test_split(X_train_raw, Y_train, test_size=0.3, random_state=42)\n",
    "                X_train_tfidf, X_val_tfidf = n_gram_tfidf(X_train, X_val, n)\n",
    "                feature_size = X_train_tfidf.shape[1]\n",
    "                X_train_smp, Y_train_smp = sampling(X_train_tfidf, y_train, sm)\n",
    "                \n",
    "                # sub-sample the validation set to obtain a balanced dataset\n",
    "                X_val_tfidf, y_val = sampling(X_val_tfidf, y_val, sampling_method = 'under')\n",
    "                \n",
    "                X_train_kBest, X_val_kBest = kBest_chi2(int(0.1*feature_size), X_train_smp, Y_train_smp, X_val_tfidf)\n",
    "\n",
    "                clf.fit(X_train_kBest, Y_train_smp)\n",
    "                prediction = clf.predict(X_val_kBest)\n",
    "                \n",
    "                acc.append(accuracy_score(y_val, prediction))\n",
    "                f1.append(f1_score(y_val, prediction, average='macro'))\n",
    "                \n",
    "            acc_list.append(acc)\n",
    "            f1_list.append(f1)\n",
    "\n",
    "        data = {'sampling': sample, 'unigram': acc_list[0], 'bigram': acc_list[1], '1-3 gram': acc_list[2]}\n",
    "        df = pd.DataFrame(data)\n",
    "        df = df.set_index('sampling')\n",
    "        df_dict[clf_dict[clf]] = df\n",
    "    \n",
    "    for i in df_dict.keys():\n",
    "        print(i)\n",
    "        print(\"-------------------------------------------\")\n",
    "        print(df_dict[i])\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_acc(n_gram, sampling_method, clf, X_train_raw, Y_train):\n",
    "    '''\n",
    "    Create a dataframe containing different propotion of test set \n",
    "    as well as accuracy of train and test data.\n",
    "    '''\n",
    "    test_percentage = list(range(9, 0, -1))\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    for i in test_percentage:\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_raw, Y_train, test_size=i*0.1, random_state=42)\n",
    "        X_train_tfidf, X_val_tfidf = n_gram_tfidf(X_train, X_val, n_gram)\n",
    "        feature_size = X_train_tfidf.shape[1]\n",
    "\n",
    "        X_train_smp, Y_train_smp = sampling(X_train_tfidf, y_train, sampling_method)\n",
    "        \n",
    "        # sub-sample the validation set to obtain a balanced dataset\n",
    "        X_val_tfidf, y_val = sampling(X_val_tfidf, y_val, sampling_method = 'under')\n",
    "        X_train_kBest, X_val_kBest = kBest_chi2(int(0.1*feature_size), X_train_smp, Y_train_smp, X_val_tfidf)\n",
    "        \n",
    "        clf.fit(X_train_kBest, Y_train_smp)\n",
    "        train_acc.append(clf.score(X_train_kBest, Y_train_smp))\n",
    "        test_acc.append(clf.score(X_val_kBest, y_val))\n",
    "    \n",
    "    data = {'percentage': [100-10*i for i in test_percentage], 'train accuracy': train_acc, 'test accuracy': test_acc}\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.set_index('percentage')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to see the accuracy of each model versus different k values\n",
    "# You can adjust the parameters 'n_gram': {1,2,3} and 'sampling_method': {None, 'under', 'over'}\n",
    "\n",
    "# accuracy_k(1, 'under', X_train_raw, Y_train)\n",
    "\n",
    "\n",
    "# Uncomment lines below to see accuracy/f1 comparison for different combination of n-gram and sampling methods\n",
    "# Change the parameter 'accuracy' to 'f1' to see f1 score comparison\n",
    "\n",
    "# clf_dict = {zero_r:\"Zero-R\", bnb: \"Bernolli Naive Bayes\", knn5: \"K Nearest Neighbour\", \n",
    "#             lg_clf: \"Logistic Regression\", svm: \"SVM\", stk_clf: \"Stacking\"}\n",
    "# preprocess_cmp(scoring = 'accuracy')\n",
    "\n",
    "\n",
    "# Uncomment lines below to see the learning curve for five models\n",
    "\n",
    "# clf_dict = {bnb: \"BNB\", knn5: \"KNN\", lg_clf: \"LG\", svm: \"SVM\", stk_clf: \"STK\"}\n",
    "# for clf in clf_dict:\n",
    "#     df = train_test_acc(1, 'under', clf, X_train_raw, Y_train)\n",
    "#     plot_line(df, f'lc_{clf_dict[clf].lower()}.png', f'Learning Curve ({clf_dict[clf]})', \"% of training instances\", \"Accuracy\")\n",
    "#     print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
